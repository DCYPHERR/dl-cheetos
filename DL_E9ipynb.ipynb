{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **EXPERIMENT 9**"
      ],
      "metadata": {
        "id": "Fhm8VEQUR5UP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GAN MNIST**"
      ],
      "metadata": {
        "id": "M9kjyREk8z0E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r8B-hNTq3l68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc27defa-271f-4e59-a7f1-157fb45c0996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-bc4f54eea6bd>:8: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
            "  display.set_matplotlib_formats('svg')\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "display.set_matplotlib_formats('svg')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "362mWz6a7H1F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n",
        "data = data[:,1:]\n",
        "dataNorm = data / np.max(data)\n",
        "dataNorm = 2*dataNorm - 1"
      ],
      "metadata": {
        "id": "KkUEiumQ7LQt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataT = torch.tensor( dataNorm ).float()\n",
        "batchsize = 100"
      ],
      "metadata": {
        "id": "OC-dcnA27NKV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create classes for the discriminator and generator**"
      ],
      "metadata": {
        "id": "0maBEq8b7SRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class discriminatorNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(28*28,256)\n",
        "    self.fc2 = nn.Linear(256,256)\n",
        "    self.out = nn.Linear(256,1)\n",
        "  def forward(self,x):\n",
        "    x = F.leaky_relu( self.fc1(x) )\n",
        "    x = F.leaky_relu( self.fc2(x) )\n",
        "    x = self.out(x)\n",
        "    return torch.sigmoid( x )\n",
        "dnet = discriminatorNet()\n",
        "y = dnet(torch.randn(10,784))\n",
        "y"
      ],
      "metadata": {
        "id": "TNPZ-UuD7Qeg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "class discriminatorNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(28*28, 256)\n",
        "    self.fc2 = nn.Linear(256, 256)\n",
        "    self.fc3 = nn.Linear(256, 128)   # new layer\n",
        "    self.out = nn.Linear(128, 1)     # adjust output dimension\n",
        "  def forward(self,x):\n",
        "    x = F.leaky_relu(self.fc1(x))\n",
        "    x = F.leaky_relu(self.fc2(x))\n",
        "    x = F.leaky_relu(self.fc3(x))    # pass through new layer\n",
        "    x = self.out(x)\n",
        "    return torch.sigmoid(x)\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "zkBI25DT3EA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class generatorNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(64,256)\n",
        "    self.fc2 = nn.Linear(256,256)\n",
        "    self.out = nn.Linear(256,784)\n",
        "  def forward(self,x):\n",
        "    x = F.leaky_relu( self.fc1(x) )\n",
        "    x = F.leaky_relu( self.fc2(x) )\n",
        "    x = self.out(x)\n",
        "    return torch.tanh( x )\n",
        "gnet = generatorNet()\n",
        "y = gnet(torch.randn(10,64))\n",
        "plt.imshow(y[0,:].detach().squeeze().view(28,28));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "lLQit8l27jZ2",
        "outputId": "3630ec39-50f1-4272-bdfa-0e064a8033e2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"300.237pt\" height=\"297.190125pt\" viewBox=\"0 0 300.237 297.190125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-04-26T14:03:59.069193</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 297.190125 \nL 300.237 297.190125 \nL 300.237 0 \nL -0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 273.312 \nL 293.037 273.312 \nL 293.037 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g clip-path=\"url(#pcfbafe4184)\">\n    <image xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAAXIAAAFyCAYAAADoJFEJAAAV3klEQVR4nO3c+ZfddX3H8de9c+/cO/uazJLMZE8IYBIkAYVAWAICB0FoKyCIqBzhVDxibdWerlpbCwW6QGUptVoUKViLIFSWEBYDlEAJBMkkk2VmMlkmmcns+9yZ/g2v70++T5+P31/n873f+X5f8/3plbqk6ctzMnXdsMyNaLLePkaSVLxyyM7MvltlZ0qP+Nc3l7Yjmv8/A35I0qHNNXam4e1xO7Pv8/6PKtmdszOSlB1NFLONNft/2wVbp+1M761jdkaSRo6U25mmV/y/02iTn2n6tf/+Df6V/9xJUj4zY2d6R8rszPkt7Xbm6XfX2RlJanqxyM7M3NhnZxJUEQDgtwlFDgDBUeQAEBxFDgDBUeQAEBxFDgDBUeQAEBxFDgDBUeQAEBxFDgDBUeQAEBxFDgDBpVofusNeFCrbn7UPyiTb0dHQRyftTOqEf31176fszHCrn2nZkmxYaXhR3s5kxv2xqKqvdtmZ7p8vsTOSNLR+ws4UHfEHumZq/TGm8nb/GUpP2RFJ0qYbttuZF57eYGdS/m3QbLGfKT+YbCBvusx/n5JcX+6Ef31TVf61SdLI4oKdqVvab2f4IgeA4ChyAAiOIgeA4ChyAAiOIgeA4ChyAAiOIgeA4ChyAAiOIgeA4ChyAAiOIgeA4ChyAAguU904bIcGisrtzCfXvWdnJOnXD6+3M8OL/XMquvzFo8EV/mLP4XNK7YwkVWzqsTOlf+GfdXCg2s7UX9FtZyTp5BL/2dtfX2dnjp+osDMXXvOunXlm96l2RpIOj1fZmYpOf/jp+DnTdiY9mLEzS29qtzOS1PnQSjtz7Fz/Ny14wB9ra7/B7zxJmssmGK67yz+LL3IACI4iB4DgKHIACI4iB4DgKHIACI4iB4DgKHIACI4iB4DgKHIACI4iB4DgKHIACI4iB4DgKHIACC4z+psaOzRvt39Q+jR/BUySGp/wD8tf5K+o7b/W/5928boddubFPSfZGUnKPNtgZ8qLx+zM8IC/6Dg+7mckKf8t/5no+Ut/KbD4sH992+tb7UxhOtl30b6f+s/rwJkzdqbpBX/JsHpnv53ZMeH/Hkma/xl/4bNsa6Odab+9YGfmCv46qiQVHcvZmf2/m7IzfJEDQHAUOQAER5EDQHAUOQAER5EDQHAUOQAER5EDQHAUOQAER5EDQHAUOQAER5EDQHAUOQAEl5m3wx8uyt581M5sfeQMOyNJC9LtfijBPle+O2tnni86xc6kJorsjCSNtvg/anhZ3s40PZNgyOoqf4RIkvo2LrAzubJRO1PZ7o9m9eTm25nVdx2wM5K0++5mO3PxijY7M77Of8aP3dZiZ8q6/dEnSRo97A9gjZ7sj4dp0n8HF7X0+udIyv7AHyXc92n/eeWLHACCo8gBIDiKHACCo8gBIDiKHACCo8gBIDiKHACCo8gBIDiKHACCo8gBIDiKHACCo8gBILhU6/132itJzUv9AZkje+bZGUmq2OcP3Cx41h/1mplXYWeOnF3mn1NiRyRJqTVDdqbsWf83zd962M50ftofv5IkJdhWGl06bWeKezJ2prB0ws6k07N2RpJKX/efo/oP/OvruDnBmtxhf3htxSP9/jmS9n7GH5hK+4+D6nf692FocbJv3pEV/gVm+v3nlS9yAAiOIgeA4ChyAAiOIgeA4ChyAAiOIgeA4ChyAAiOIgeA4ChyAAiOIgeA4ChyAAiOIgeA4DLlTSN2aPTZRjtTd7E/tCVJg6N1dqbrav/6Krr8waNUgo2kXbd+3w9JWv7orXZmYtOkn6nzB7Am1ozbGUlq/Tf/O6Kj2R8USs3661y5D/x1s7WX77IzkvT+e6vtTPf5OTsz2+c/sN+/6gd25p4nr7MzkjTX4g+Blbzp/516rvTPaX4ia2ckqWaP/+ylp2b8jJ0AAPxWocgBIDiKHACCo8gBIDiKHACCo8gBIDiKHACCo8gBIDiKHACCo8gBIDiKHACCo8gBIDiKHACCSy294+45N5Qd9he9Wn81aGckqeOb/v+aySF/GW7+q/662bGzCnameYt/7yTp8GZ/ua5sv/+bxk72l+HmJorsjCSV7/Wvr+D/abX8ov12Zu/xejszNZlsIa84N21npvdV+OcM+M/eoos77MyBXn+xVJKW1PfZmd2HGuxMzct5OzO4wo5IkgolCSZSE3xe80UOAMFR5AAQHEUOAMFR5AAQHEUOAMFR5AAQHEUOAMFR5AAQHEUOAMFR5AAQHEUOAMFR5AAQXKb6VH+oJvfDGjvT9cfJxqKUYHMmlbF3wDRe719fRXvGzuT7Ju2MJLX8tz9M1bPevw9nLO+wM2+/udLOSNJsgo2p2l3+UFnn8FI7M75qxs4k/Sya6C+2M/Wn9tqZW5a+Zmfuv+sqO5PPJ3vXd32kxM7ULxywM70b/Pc2XZbgeZBU1O0PdP3Rlb+wM3yRA0BwFDkABEeRA0BwFDkABEeRA0BwFDkABEeRA0BwFDkABEeRA0BwFDkABEeRA0BwFDkABJdqffBOe1mpcrc/OjOzcdDOSNJYvz+kc+naD+zMh/2Ndubx1T+xM5//2O/ZGUnquHGxnZmY5y+OzZb5o1Q1O/znQZJS/lE6sd4fL2p6yR8cm6j2h59mLhmwM5I03FtmZ2q3J1gcS2AmwQBWkjE0SUr5G28aWTthZ6qqxuxMWW7KzkjS4fZ5fijB5zVf5AAQHEUOAMFR5AAQHEUOAMFR5AAQHEUOAMFR5AAQHEUOAMFR5AAQHEUOAMFR5AAQHEUOAMGlWv/lDnuqpqLNX8XJ9yVYxJHUf4qfaX7NX2NKFfzrm6zyx5iOf9QfIZKkQoX/m8obRuzMgr/xf1PnpRV2RpKmav1Rr1X39diZXX/gDxfNW9RvZ0ZeTzCQJKl6r38fBpb732D15x6xM91tDXYmyfiVJM1728/0XOCPqM17xe+vqapk7+3QMv9ve9K9/jPOFzkABEeRA0BwFDkABEeRA0BwFDkABEeRA0BwFDkABEeRA0BwFDkABEeRA0BwFDkABEeRA0BwiUazvnr2C/ZB//zMpXZGkkoP+WM12RF/tSd9da+d6e31x6K+tn6LnZGkB3dvtDPZl6rsTEmvP/IzXpfse2Cizs8UDyc4p95/Hir3+uf0XzTuhyTVP5O3M9Nl/ntR//6onek+v9zOjC3yh6wkKVs1aWfOWNRpZ17fs8zOzM0mG82qf80f6Bpc6Z/DFzkABEeRA0BwFDkABEeRA0BwFDkABEeRA0BwFDkABEeRA0BwFDkABEeRA0BwFDkABEeRA0BwFDkABJcp7fDXucY+lrMz5av67YwkNTyesTPt1/uLbanBMjuz5Ef+ItqPt1xmZyQpXe+fVX6oYGcOXWhHNJdOuHY3VGRnVlzUbmf2PebPyY012RE1P17shyQN3jRoZ3L/VW1nigb9dcbsqP8uJVX6hv8ObhteYWeKj/mdku9Ltn6olL+8ufwef3qTL3IACI4iB4DgKHIACI4iB4DgKHIACI4iB4DgKHIACI4iB4DgKHIACI4iB4DgKHIACI4iB4DgUid/8x571WV6/bB9UGF/svGd8m5/rGb+W/71dV7uX990uT+IU77UH0iSpJEDVXYmf9z/P53v83/TVGWyQaGRldN+KMEIUUmHP2ZVyPnnXHvFq3ZGkqqK/DGr+7ZcbGcWntRjZw521duZ0v3+EJ8kzZ0+ZGey2yrtzEyJHdF4sz9AJ0lzuVk7UzFvxM7wRQ4AwVHkABAcRQ4AwVHkABAcRQ4AwVHkABAcRQ4AwVHkABAcRQ4AwVHkABAcRQ4AwVHkABBcJnVWvx0qebHGzpQdTTY6U8j6g0w1f3/Izhx/ZJWdab620860vbPIzkhSyTH/f+7EGn+MaeZA3s40bDhiZySpeMofV+rv8J+9lL9bpOJh/7nbdvuZ/kGS9l2TsTO5plE7U37NCTtT9CeNdmb+/07ZGUnqXJWzMwsuP2hn6vL+vdu+faWdkaTaHf7ftn+T/w7yRQ4AwVHkABAcRQ4AwVHkABAcRQ4AwVHkABAcRQ4AwVHkABAcRQ4AwVHkABAcRQ4AwVHkABBc6hM1X5xzQ4dvPMU+aP47Y3ZGkrrPL02Uc1W3+8tK1bd22Zm2nS12RpLKuovszNpPfWhntm9dbWdm/UuTJFX4m2Man++PWW287D078/ZR/+802F1lZySp6kP/BqZm7ddWQ8v9zLKvv2lnDvztx+2MJK3buMfO7HzeH7srOe7fh+ky/7lLKsnIG1/kABAcRQ4AwVHkABAcRQ4AwVHkABAcRQ4AwVHkABAcRQ4AwVHkABAcRQ4AwVHkABAcRQ4AwaVaf/g9e0GmfFfOPihz9gk7I0nD7dV2Zi7BiNOXNm+xMw9s32RncgeL7YwkLXx5ws7su86/EUt+5g8KdX9hys5IUl3VqJ3JZ2bszODPm+3M0DnjdqamMtkwXN/+mkQ5W6V/71InsnamaZv/DElSrt+/vrrvdNiZd7avsDOzZQU7I0k3nbnNzjz6lN8rfJEDQHAUOQAER5EDQHAUOQAER5EDQHAUOQAER5EDQHAUOQAER5EDQHAUOQAER5EDQHAUOQAER5EDQHCpNV++x54qGzjVXym7+sy37Ywkbe9dZGcmZjJ2ZmBnvZ2ZrvYX0bIDCaYZJU1X+Wc1b/X/T6en/eW6ip3H7Iwkja3w73npNw7ZmbauRjszN5uyM6lR/7mTJJX771O6z18lLJTO2pnyff5vqtp81M5IUsn3quzMqrs+tDNvHPU7pfE2fw1Tktq+tsDO3HD+a3aGL3IACI4iB4DgKHIACI4iB4DgKHIACI4iB4DgKHIACI4iB4DgKHIACI4iB4DgKHIACI4iB4DgUq3332mvJLU+6x90/LRkg0KZ0/vtTGv1gJ3p/OUSO5NE07bRRLn0jD941H59mZ1J+dtcuuUTL/ghSQ++d66dKQz7Y1FLn/B/1GzW/8YZak32jI81+wNdEw3+0NaqVf7g2MpKfxDtuX2r7YwkrW7ssTNH/nWpnaluG7EzQ98eszOSdLy/ws7M9ufsDF/kABAcRQ4AwVHkABAcRQ4AwVHkABAcRQ4AwVHkABAcRQ4AwVHkABAcRQ4AwVHkABAcRQ4AwWUq2/2hny/d/R925sX+k+2MJH2j8Tk7c+tXbrczJbX2dpi++2cP25nb6m62M5JUdtAfVqrc658zWeNn7n95sx+SlKmbsDOFjD8e1rPBHyEab/DP2Xz2DjsjSW3f+YidOe+vt9mZf3/zLDtzuKHSzuTfLLczktTbVWJnBtb555T05u3Mkspu/yBJve/NtzO5cf9d54scAIKjyAEgOIocAIKjyAEgOIocAIKjyAEgOIocAIKjyAEgOIocAIKjyAEgOIocAIKjyAEguNS5l95hr0UNLvGHttIzdkSSdGKtP16UnvRHZ+pX99qZ4ycq7Ewq7Y9zSVLJjlI7k57yzxlZP25nmp4s9g+SNLi4yM4suKzTznQ/v8jOVJ131M4c7qyzM5K0+p5+O9N2m3/WopP83zTy02Y7M7jSjkiSZlv8EbWFP/G7aGBZ1s40bB+xM5KkWf9977jCHx3jixwAgqPIASA4ihwAgqPIASA4ihwAgqPIASA4ihwAgqPIASA4ihwAgqPIASA4ihwAgqPIASA4ihwAgsv03jJqh2beq7Yz6Uk7IkmqWDhkZ4aHSuxM7df9xcSK+/zFxH27/DU5Saq8wF+u632nwc6UlPqTiX3XJJu2LBT8e76+tsvOHEz564fZe/11weol/qqeJA2sq7czte/7925ma6OdGV3tn9PyfLKX/dB5eTvT+Sn/2ct32xENLvfXRyVp8x9uszMHnzjHzvBFDgDBUeQAEBxFDgDBUeQAEBxFDgDBUeQAEBxFDgDBUeQAEBxFDgDBUeQAEBxFDgDBUeQAEFwm/3SVHapuH7czo805OyNJk33VdiY/3x/6ObrJv77+9oKdOW3NfjsjSR++vNzOzCyZsDM1eX/wqKer1s5IUuOr/nfEo1Mb7Mxciz+s1FfwB7AuufYNOyNJb/25/5vG6zJ25vJvv2RnXjm/1c4M/tjvFElKb/NHvXLV/jM+OeE/d4MqsjOS9HjbaXamtmPWzvBFDgDBUeQAEBxFDgDBUeQAEBxFDgDBUeQAEBxFDgDBUeQAEBxFDgDBUeQAEBxFDgDBUeQAEFyq9YE75+zQlN//FQeS/c9I+btUkr+ZpfM+95adee6pM+xM/rgdkSSNN9p/JpUc829EZtQ/Z6wpwQ2XJP8ofeWzv7AzD/3TFXZmZLEdUdF4svtQetS/EZUd03amd02xnRlt8V/A7GCyd714yL9/tW3+INqx0/3Bsanl/lCgJFW8VWJnhpcwmgUA/+9Q5AAQHEUOAMFR5AAQHEUOAMFR5AAQHEUOAMFR5AAQHEUOAMFR5AAQHEUOAMFR5AAQXGrxP95lL/YUjfnjNnP+To0kKT3lZ/K9/vVNVfnnZBLs6Iws8Ud+JCUaAlu9qtvOHPnPxXam7PKjdkaSMvfW2ZmD1/n3L3U0Z2cKtf45RbkkC2/SyuYeO9P2fqudSflbTPrkuW/bmTf+YYN/kKRjZ/v3LzXjvxgN2/zMRE2yb97hs/2SSBf594EvcgAIjiIHgOAocgAIjiIHgOAocgAIjiIHgOAocgAIjiIHgOAocgAIjiIHgOAocgAIjiIHgOAydTv8AZmCv0Gk0QtH/JCkbNYfkBnqLbMzi560I1KCEaLMWDbBQVJpj38fdqUX2JnsQntDTQ+veszOSNL1n/uinZkd8R++7LT/jGcOFtuZ6coED4SkI68vtjPNR/3noX9lkZ15/skz7EwuwQCdJK1d3WlnDjy5zM7M5P1nfKzZz0jS7699xc7sH59nZ/giB4DgKHIACI4iB4DgKHIACI4iB4DgKHIACI4iB4DgKHIACI4iB4DgKHIACI4iB4DgKHIACI4iB4DgUjdv/6w96/XG4cX2QXOv19gZSWp91F9EmyvxF/IO/Z2fGe6qtDO/s/EtOyNJv3zq43Zm8c9O2Jn+O2fszNRT/lqbJI0u9DOL//QNO3PoW2fZmdKj/trd8Y/5i4SS1LzFX2ccafaXDKf9x1WFBEuBGy/c6R8k6fVfrbEzU9X+4uRczZSdKe5MMPkqqXjQ/9uWbe6xM3yRA0BwFDkABEeRA0BwFDkABEeRA0BwFDkABEeRA0BwFDkABEeRA0BwFDkABEeRA0BwFDkABJdqfeBOexUnPeH3/2nr99oZSdr5ygo784UrX7QzP3rsIjszXeUPCmWH/BEdScqM+5nJM0bszIaWLjvzVuciOyNJ1c+V2pmhJQnuX8r/OxWN++c0vzZmZySp+wL/Ppxy0R47885vltqZ8r0ZOzO2LsHDKql4T4mdmSn1/7azCYbA5rJ+RpLmShIMqU35/coXOQAER5EDQHAUOQAER5EDQHAUOQAER5EDQHAUOQAER5EDQHAUOQAER5EDQHAUOQAER5EDQHD/B6BuVAsSFtP3AAAAAElFTkSuQmCC\" id=\"image38b7510b41\" transform=\"scale(1 -1) translate(0 -266.4)\" x=\"26.925\" y=\"-6.912\" width=\"266.4\" height=\"266.4\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m6aac149739\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m6aac149739\" x=\"31.677\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(28.49575 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m6aac149739\" x=\"79.197\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <g transform=\"translate(76.01575 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m6aac149739\" x=\"126.717\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <g transform=\"translate(120.3545 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m6aac149739\" x=\"174.237\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(167.8745 287.910437) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m6aac149739\" x=\"221.757\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <g transform=\"translate(215.3945 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m6aac149739\" x=\"269.277\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(262.9145 287.910437) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"md1ad8bfd1f\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#md1ad8bfd1f\" x=\"26.925\" y=\"11.952\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 15.751219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#md1ad8bfd1f\" x=\"26.925\" y=\"59.472\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 63.271219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#md1ad8bfd1f\" x=\"26.925\" y=\"106.992\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 110.791219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#md1ad8bfd1f\" x=\"26.925\" y=\"154.512\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 158.311219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#md1ad8bfd1f\" x=\"26.925\" y=\"202.032\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 205.831219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#md1ad8bfd1f\" x=\"26.925\" y=\"249.552\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 253.351219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 273.312 \nL 26.925 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 293.037 273.312 \nL 293.037 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 273.312 \nL 293.037 273.312 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 293.037 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pcfbafe4184\">\n   <rect x=\"26.925\" y=\"7.2\" width=\"266.112\" height=\"266.112\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "class generatorNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(64, 256)\n",
        "    self.fc2 = nn.Linear(256, 256)\n",
        "    self.fc3 = nn.Linear(256, 128)   # new layer\n",
        "    self.out = nn.Linear(128, 784)   # adjust output dimension\n",
        "  def forward(self,x):\n",
        "    x = F.leaky_relu(self.fc1(x))\n",
        "    x = F.leaky_relu(self.fc2(x))\n",
        "    x = F.leaky_relu(self.fc3(x))    # pass through new layer\n",
        "    x = self.out(x)\n",
        "    return torch.tanh(x)\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "FF2S4vQO4rpX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the models!**"
      ],
      "metadata": {
        "id": "43pjAuZz7rBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lossfun = nn.BCELoss() #can make change here\n",
        "dnet = discriminatorNet().to(device)\n",
        "gnet = generatorNet().to(device)\n",
        "d_optimizer = torch.optim.Adam(dnet.parameters(), lr=.0003) #change lr\n",
        "g_optimizer = torch.optim.Adam(gnet.parameters(), lr=.0003) #change lr\n",
        "num_epochs = 50000 \n",
        "losses = np.zeros((num_epochs,2))\n",
        "disDecs = np.zeros((num_epochs,2)) \n",
        "for epochi in range(num_epochs):\n",
        "  randidx = torch.randint(dataT.shape[0],(batchsize,))\n",
        "  real_images = dataT[randidx,:].to(device)\n",
        "  fake_images = gnet( torch.randn(batchsize,64).to(device) ) \n",
        "  real_labels = torch.ones(batchsize,1).to(device)\n",
        "  fake_labels = torch.zeros(batchsize,1).to(device)\n",
        "  pred_real = dnet(real_images)\n",
        "  d_loss_real = lossfun(pred_real,real_labels) \n",
        "  pred_fake = dnet(fake_images)\n",
        "  d_loss_fake = lossfun(pred_fake,fake_labels) \n",
        "  d_loss = d_loss_real + d_loss_fake\n",
        "  losses[epochi,0] = d_loss.item()\n",
        "  disDecs[epochi,0] = torch.mean((pred_real>.5).float()).detach()\n",
        "  # backprop\n",
        "  d_optimizer.zero_grad()\n",
        "  d_loss.backward()\n",
        "  d_optimizer.step()\n",
        "  fake_images = gnet( torch.randn(batchsize,64).to(device) )\n",
        "  pred_fake = dnet(fake_images)\n",
        "  g_loss = lossfun(pred_fake,real_labels)\n",
        "  losses[epochi,1] = g_loss.item()\n",
        "  disDecs[epochi,1] = torch.mean((pred_fake>.5).float()).detach()\n",
        "  g_optimizer.zero_grad()\n",
        "  g_loss.backward()\n",
        "  g_optimizer.step()  \n",
        "  if (epochi+1)%500==0:\n",
        "    msg = f'Finished epoch {epochi+1}/{num_epochs}'\n",
        "    sys.stdout.write('\\r' + msg)\n",
        "\n",
        "fig,ax = plt.subplots(1,3,figsize=(18,5))\n",
        "ax[0].plot(losses)\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Loss')\n",
        "ax[0].set_title('Model loss')\n",
        "ax[0].legend(['Discrimator','Generator'])\n",
        "ax[1].plot(losses[::5,0],losses[::5,1],'k.',alpha=.1)\n",
        "ax[1].set_xlabel('Discriminator loss')\n",
        "ax[1].set_ylabel('Generator loss')\n",
        "ax[2].plot(disDecs)\n",
        "ax[2].set_xlabel('Epochs')\n",
        "ax[2].set_ylabel('Probablity (\"real\")')\n",
        "ax[2].set_title('Discriminator output')\n",
        "ax[2].legend(['Real','Fake'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "Wh50vUjY7u7e",
        "outputId": "02e8e042-4885-492f-e769-0e97c7f37271"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished epoch 11000/50000"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d8ff4ba3bdfd>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;31m# backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0md_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   \u001b[0md_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mfake_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnet\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "lossfun = nn.MSELoss()   # use mean squared error loss\n",
        "dnet = discriminatorNet().to(device)\n",
        "gnet = generatorNet().to(device)\n",
        "d_optimizer = torch.optim.Adam(dnet.parameters(), lr=.0003)\n",
        "g_optimizer = torch.optim.Adam(gnet.parameters(), lr=.0003)\n",
        "num_epochs = 10000    # change number of epochs to 10000\n",
        "losses = np.zeros((num_epochs,2))\n",
        "disDecs = np.zeros((num_epochs,2)) \n",
        "for epochi in range(num_epochs):\n",
        "  randidx = torch.randint(dataT.shape[0],(batchsize,))\n",
        "  real_images = dataT[randidx,:].to(device)\n",
        "  fake_images = gnet(torch.randn(batchsize,64).to(device))\n",
        "  real_labels = torch.ones(batchsize,1).to(device)\n",
        "  fake_labels = torch.zeros(batchsize,1).to(device)\n",
        "  pred_real = dnet(real_images)\n",
        "  d_loss_real = lossfun(pred_real,real_labels) \n",
        "  pred_fake = dnet(fake_images)\n",
        "  d_loss_fake = lossfun(pred_fake,fake_labels) \n",
        "  d_loss = d_loss_real + d_loss_fake\n",
        "  losses[epochi,0] = d_loss.item()\n",
        "  disDecs[epochi,0] = torch.mean((pred_real>.5).float()).detach()\n",
        "  # backprop\n",
        "  d_optimizer.zero_grad()\n",
        "  d_loss.backward()\n",
        "  d_optimizer.step()\n",
        "  fake_images = gnet(torch.randn(batchsize,64).to(device))\n",
        "  pred_fake = dnet(fake_images)\n",
        "  g_loss = lossfun(pred_fake,real_labels)\n",
        "  losses[epochi,1] = g_loss.item()\n",
        "  disDecs[epochi,1] = torch.mean((pred_fake>.5).float()).detach()\n",
        "  g_optimizer.zero_grad()\n",
        "  g_loss.backward()\n",
        "  g_optimizer.step()  \n",
        "  if (epochi+1)%500==0:\n",
        "    msg = f'Finished epoch {epochi+1}/{num_epochs}'\n",
        "    sys.stdout.write('\\r' + msg)\n",
        "\n",
        "fig,ax = plt.subplots(1,3,figsize=(18,5))\n",
        "ax[0].plot(losses)\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Loss')\n",
        "ax[0].set_title('Model loss')\n",
        "ax[0].legend(['Discrimator','Generator'])\n",
        "ax[1].plot(losses[::5,0],losses[::5,1],'k.',alpha=.1)\n",
        "ax[1].set_xlabel('Discriminator loss')\n",
        "ax[1].set_ylabel('Generator loss')\n",
        "ax[2].plot(disDecs)\n",
        "ax[2].set_xlabel('Epochs')\n",
        "ax[2].set_ylabel('Probablity (\"real\")')\n",
        "ax[2].set_title('Discriminator output')\n",
        "ax[2].legend(['Real','Fake'])\n",
        "plt.show()\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "rQk9lBZw5Pu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gnet.eval()\n",
        "fake_data = gnet(torch.randn(12,64).to(device)).cpu()\n",
        "fig,axs = plt.subplots(3,4,figsize=(8,6))\n",
        "for i,ax in enumerate(axs.flatten()):\n",
        "  ax.imshow(fake_data[i,:,].detach().view(28,28),cmap='gray')\n",
        "  ax.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iwykZSlb8uxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0qfgWeHR76LY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}