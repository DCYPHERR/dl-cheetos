{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JW-FpvDB-Anb"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Explore the LSTM type"
      ],
      "metadata": {
        "id": "RnWOVx-e-4zJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_size = 9  \n",
        "hidden_size = 16\n",
        "num_layers = 2   #change here\n",
        "\n",
        "lstm = nn.LSTM(input_size,hidden_size,num_layers)\n",
        "lstm\n",
        "nn.LSTM\n",
        "\n",
        "seqlength = 5\n",
        "batchsize = 2\n",
        "\n",
        "X = torch.rand(seqlength,batchsize,input_size)\n",
        "\n",
        "H = torch.zeros(num_layers,batchsize,hidden_size)\n",
        "C = torch.zeros(num_layers,batchsize,hidden_size)\n",
        "\n",
        "hiddeninputs = (H,C)\n",
        "\n",
        "y,h = lstm(X,hiddeninputs)\n",
        "print(f' Input shape: {list(X.shape)}')\n",
        "print(f'Hidden shape: {list(h[0].shape)}')\n",
        "print(f' Cell shape: {list(h[1].shape)}')\n",
        "print(f'Output shape: {list(y.shape)}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTnrxIeq_LkK",
        "outputId": "60d9883c-5e18-4236-d828-625a4d5a1434"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Input shape: [5, 2, 9]\n",
            "Hidden shape: [5, 2, 16]\n",
            " Cell shape: [5, 2, 16]\n",
            "Output shape: [5, 2, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create a DL model class"
      ],
      "metadata": {
        "id": "tKMjPhau_9xL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMnet(nn.Module):\n",
        "  def __init__(self,input_size,num_hidden,num_layers):\n",
        "    super().__init__()\n",
        "\n",
        "    \n",
        "    self.input_size = input_size\n",
        "    self.num_hidden = num_hidden\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "   \n",
        "    self.lstm = nn.LSTM(input_size,num_hidden,num_layers)\n",
        "    self.out = nn.Linear(num_hidden,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    print(f'Input: {list(x.shape)}')\n",
        "    y,hidden = self.lstm(x)\n",
        "    print(f'RNN-out: {list(y.shape)}')\n",
        "    print(f'RNN-hidden: {list(hidden[0].shape)}')\n",
        "    print(f'RNN-cell: {list(hidden[1].shape)}')\n",
        "    o = self.out(y)\n",
        "    print(f'Output: {list(o.shape)}')\n",
        "\n",
        "    return o,hidden\n",
        "\n",
        "net = LSTMnet(input_size,hidden_size,num_layers)\n",
        "print(net), print(' ')\n",
        "\n",
        "net = LSTMnet(input_size,hidden_size,num_layers)\n",
        "print(net), print(' ')\n",
        "\n",
        "for p in net.named_parameters():\n",
        "  print(f'{p[0]:>20} has size {list(p[1].shape)}')\n",
        "  \n",
        "X = torch.rand(seqlength,batchsize,input_size)\n",
        "y = torch.rand(seqlength,batchsize,1)\n",
        "yHat,h = net(X)\n",
        "\n",
        "lossfun = nn.MSELoss()\n",
        "lossfun(yHat,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFGhKR_9_9VD",
        "outputId": "e1e829ce-f8a0-4f29-a9c6-c888d3503652"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMnet(\n",
            "  (lstm): LSTM(9, 16, num_layers=5)\n",
            "  (out): Linear(in_features=16, out_features=1, bias=True)\n",
            ")\n",
            " \n",
            "LSTMnet(\n",
            "  (lstm): LSTM(9, 16, num_layers=5)\n",
            "  (out): Linear(in_features=16, out_features=1, bias=True)\n",
            ")\n",
            " \n",
            "   lstm.weight_ih_l0 has size [64, 9]\n",
            "   lstm.weight_hh_l0 has size [64, 16]\n",
            "     lstm.bias_ih_l0 has size [64]\n",
            "     lstm.bias_hh_l0 has size [64]\n",
            "   lstm.weight_ih_l1 has size [64, 16]\n",
            "   lstm.weight_hh_l1 has size [64, 16]\n",
            "     lstm.bias_ih_l1 has size [64]\n",
            "     lstm.bias_hh_l1 has size [64]\n",
            "   lstm.weight_ih_l2 has size [64, 16]\n",
            "   lstm.weight_hh_l2 has size [64, 16]\n",
            "     lstm.bias_ih_l2 has size [64]\n",
            "     lstm.bias_hh_l2 has size [64]\n",
            "   lstm.weight_ih_l3 has size [64, 16]\n",
            "   lstm.weight_hh_l3 has size [64, 16]\n",
            "     lstm.bias_ih_l3 has size [64]\n",
            "     lstm.bias_hh_l3 has size [64]\n",
            "   lstm.weight_ih_l4 has size [64, 16]\n",
            "   lstm.weight_hh_l4 has size [64, 16]\n",
            "     lstm.bias_ih_l4 has size [64]\n",
            "     lstm.bias_hh_l4 has size [64]\n",
            "          out.weight has size [1, 16]\n",
            "            out.bias has size [1]\n",
            "Input: [5, 2, 9]\n",
            "RNN-out: [5, 2, 16]\n",
            "RNN-hidden: [5, 2, 16]\n",
            "RNN-cell: [5, 2, 16]\n",
            "Output: [5, 2, 1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1622, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "net = LSTMnet(input_size, hidden_size, num_layers)\n",
        "print(net)\n",
        "print()\n",
        "\n",
        "for p in net.named_parameters():\n",
        "  print(f'{p[0]:>20} has size {list(p[1].shape)}')\n",
        "\n",
        "X = torch.rand(seqlength, batchsize, input_size)\n",
        "y = torch.rand(seqlength, batchsize, 1)\n",
        "yHat, h = net(X)\n",
        "\n",
        "# Changing the loss function to Mean Absolute Error (MAE)\n",
        "lossfun = nn.L1Loss()\n",
        "loss = lossfun(yHat, y)\n",
        "print(loss)\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "YqU5WqdY0rLY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###GRU"
      ],
      "metadata": {
        "id": "s4NvwfzCAx13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gru = nn.GRU(input_size,hidden_size,num_layers)\n",
        "gru\n",
        "\n",
        "nn.GRU\n",
        "X = torch.rand(seqlength,batchsize,input_size)\n",
        "H = torch.zeros(num_layers,batchsize,hidden_size)\n",
        "\n",
        "y,h = gru(X,H) \n",
        "print(f' Input shape: {list(X.shape)}')\n",
        "print(f'Hidden shape: {list(h.shape)}')\n",
        "print(f'Output shape: {list(y.shape)}')\n",
        "\n",
        "for p in gru.named_parameters():\n",
        "  print(f'{p[0]:>15} has size {list(p[1].shape)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIEwm2fBAzY7",
        "outputId": "c6f03d07-c5b2-4d03-bec3-1635cfb8c3bb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Input shape: [5, 2, 9]\n",
            "Hidden shape: [5, 2, 16]\n",
            "Output shape: [5, 2, 16]\n",
            "   weight_ih_l0 has size [48, 9]\n",
            "   weight_hh_l0 has size [48, 16]\n",
            "     bias_ih_l0 has size [48]\n",
            "     bias_hh_l0 has size [48]\n",
            "   weight_ih_l1 has size [48, 16]\n",
            "   weight_hh_l1 has size [48, 16]\n",
            "     bias_ih_l1 has size [48]\n",
            "     bias_hh_l1 has size [48]\n",
            "   weight_ih_l2 has size [48, 16]\n",
            "   weight_hh_l2 has size [48, 16]\n",
            "     bias_ih_l2 has size [48]\n",
            "     bias_hh_l2 has size [48]\n",
            "   weight_ih_l3 has size [48, 16]\n",
            "   weight_hh_l3 has size [48, 16]\n",
            "     bias_ih_l3 has size [48]\n",
            "     bias_hh_l3 has size [48]\n",
            "   weight_ih_l4 has size [48, 16]\n",
            "   weight_hh_l4 has size [48, 16]\n",
            "     bias_ih_l4 has size [48]\n",
            "     bias_hh_l4 has size [48]\n"
          ]
        }
      ]
    }
  ]
}